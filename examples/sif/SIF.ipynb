{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SIF Explainer Tutorial\n",
    "#### This tutorial illustrates the use of SIF algorithm, a comprehensive single-valued metric, to measure outlier impacts on future predictions. It provides a quantitative measure regarding the outlier impacts,  which can be used in a variety of scenarios, such as the evaluation of outlier detection methods, the creation of more harmful outliers, etc. This is a demonstration for AAAI-2021 paper [Outlier Impact Characterization for Time Series Data](https://ojs.aaai.org/index.php/AAAI/article/view/17379).\n",
    "#### SIF algorithm mainly tackles the challenge of outlier interpretation in time series data via [contamination processes](https://www.jstor.org/stable/pdf/3035535.pdf). It assumes that the observed input time series is obtained from separate processes for both the core input and the recurring outliers, i.e., the core process and the contaminating process. At each time stamp, with a certain (small) probability, the observed value of the contaminated process comes from the contaminating process, which corresponds to the outliers. The SIF algorithm focuses on the generic patchy outliers where the outlying patterns can be present over consecutive time stamps, and aims to study the impact of the contaminating process on both parameter estimation and future value prediction.\n",
    "#### The tutorial is organized as folows:\n",
    "#### 1. [Train a Model Inherited from SIFExplainer](https://github.com/Leo02016/AIX360/blob/dc0efab88b90f225427347b080897a3e19792403/examples/sif/SIF.ipynb#L12)\n",
    "#### 2. [Initialize the Required Parameters and Synthesize the Dataset](https://github.com/Leo02016/AIX360/blob/dc0efab88b90f225427347b080897a3e19792403/examples/sif/SIF.ipynb#L61)\n",
    "#### 3. [Interpret the Model by SIF Value](https://github.com/Leo02016/AIX360/blob/dc0efab88b90f225427347b080897a3e19792403/examples/sif/SIF.ipynb#L139)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Train a Model Inherited from SIFExplainer\n",
    "#### First, we define a function that trains a AR2 model inherited from SIFExplainer and this model (AR2) is what we are going to interpret. Notice that the AR2 model below can be changed to AllLSTM or AllRNN model defined in SIF_NN.py file. AllRNN, AllLSTM, AllAR are also inherited from SIFExplainer Model defined in SIF.py file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.tsa.api as smt\n",
    "import matplotlib.pyplot as plt\n",
    "from aix360.datasets.SIF_dataset import DataSetTS\n",
    "from aix360.algorithms.sif.SIF_NN import AllRNN, AllLSTM, AllAR\n",
    "from aix360.algorithms.sif.SIF_utils import get_contaminate_series\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# arma2 model\n",
    "def get_model_train_ar2(data_sets, series, timesteps, w=None, gammas=None, num_train_steps=20000,\n",
    "                        model_dir=None):\n",
    "    initial_learning_rate = 0.01\n",
    "    decay_epochs = [10000, 20000]\n",
    "    batch_size = 20\n",
    "    n_sample = series.shape[1] if len(series.shape) > 1 else 1\n",
    "\n",
    "    # model can be changed to AllLSTM or AllRNN model defined in SIF_NN.py\n",
    "    model = AllAR(\n",
    "        time_steps=timesteps,\n",
    "        x_dim=n_sample,\n",
    "        y_dim=n_sample,\n",
    "        share_param=True,\n",
    "        batch_size=batch_size,\n",
    "        time_series=series,\n",
    "        data_sets=data_sets,\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        damping=1e-3,\n",
    "        decay_epochs=decay_epochs,\n",
    "        mini_batch=False,\n",
    "        train_dir='arma_output',\n",
    "        log_dir='logs',\n",
    "        model_name='ar_test',\n",
    "        calc_hessian=False,\n",
    "        w=w,\n",
    "        gammas=gammas,\n",
    "    )\n",
    "    if model_dir is not None:\n",
    "        print('Loading pre-trained model......')\n",
    "        model.restore(model_dir)\n",
    "    else:\n",
    "        model.train(num_steps=num_train_steps, iter_to_switch_to_batch=10, iter_to_switch_to_sgd=10)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Initialize the Required Parameters and Synthesize the Dataset\n",
    "#### In the second step, we initialize the parameters for SIFExplainer. \n",
    "#### By default, we use the fast mode to accelerate the computation. In the fast mode, we load the pre-trained AR2 model and dataset to skip training stage. If the user plans to retrain the AR2 model, please set the parameter [fast_mode](https://github.com/Leo02016/AIX360/blob/dc0efab88b90f225427347b080897a3e19792403/examples/sif/SIF.ipynb#L65) to be False. Then, the algorithm will generate a new synthetic dataset and train AR2 model from scratch.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "fast_mode = True\n",
    "\n",
    "# parameters\n",
    "timesteps = 2\n",
    "np.random.seed(1)\n",
    "n_sample = 1000\n",
    "n_time_stamp = 100\n",
    "gammas = np.arange(0.0, 0.09, 0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Please ensure that data.pkl and model are downloaded in the following directories."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_dir = '../../aix360/data/sif_data/data.pkl'\n",
    "model_dir = '../../aix360/models/sif/ar2'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Skip generating the synthetic dataset and training the model if using fast-mode. In the fast mode, we directly load the saved dataset and pre-trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Documents\\GitHub\\AIX360\\aix360\\algorithms\\sif\\SIF_NN.py:18: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Documents\\GitHub\\AIX360\\aix360\\algorithms\\sif\\SIF.py:29: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Documents\\GitHub\\AIX360\\aix360\\algorithms\\sif\\SIF_NN.py:38: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Documents\\GitHub\\AIX360\\aix360\\algorithms\\sif\\SIF.py:649: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Documents\\GitHub\\AIX360\\aix360\\algorithms\\sif\\SIF.py:654: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Anaconda3\\envs\\tf_115\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Documents\\GitHub\\AIX360\\aix360\\algorithms\\sif\\SIF.py:657: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Documents\\GitHub\\AIX360\\aix360\\algorithms\\sif\\SIF.py:659: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Documents\\GitHub\\AIX360\\aix360\\algorithms\\sif\\SIF.py:96: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Documents\\GitHub\\AIX360\\aix360\\algorithms\\sif\\SIF.py:614: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Documents\\GitHub\\AIX360\\aix360\\algorithms\\sif\\SIF.py:625: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Documents\\GitHub\\AIX360\\aix360\\algorithms\\sif\\SIF.py:104: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\lecheng4\\Documents\\GitHub\\AIX360\\aix360\\algorithms\\sif\\SIF.py:161: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n\n",
      "Total number of parameters: 2\nLoading pre-trained model......\nINFO:tensorflow:Restoring parameters from ../../aix360/models/sif/ar2\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "if fast_mode:\n",
    "    assert os.path.exists(data_dir), \"Could not find the data.pkl in {}\".format(data_dir)\n",
    "    # load time series from data.pkl file\n",
    "    series = pickle.load(open(data_dir, \"rb\"))\n",
    "    data_sets = DataSetTS(np.arange(len(series)), np.array(['Y']), None, None, None,\n",
    "                          lag=timesteps).datasets_gen_rnn()\n",
    "    # initialize and train the model which takes the clean time sequence as input and makes prediction\n",
    "    model = get_model_train_ar2(data_sets, series, timesteps, gammas=gammas, model_dir=model_dir)\n",
    "else:\n",
    "    # ar and ma are two parameters controlling the synthetic time sequence data\n",
    "    ar = np.r_[1, -np.array([0.7, -0.3])]\n",
    "    ma = np.r_[1, -np.array([0.1])]\n",
    "\n",
    "    # generate the core process or clean time sequence data\n",
    "    series = [smt.arma_generate_sample(ar, ma, n_time_stamp) for i in range(n_sample)]\n",
    "    series = np.vstack(series)\n",
    "    pickle.dump(series, open(data_dir, \"wb\"))\n",
    "    data_sets = DataSetTS(np.arange(len(series)), np.array(['Y']), None, None, None,\n",
    "                          lag=timesteps).datasets_gen_rnn()\n",
    "    # initialize and train the model which takes the clean time sequence as input and makes prediction\n",
    "    model = get_model_train_ar2(data_sets, series, timesteps, gammas=gammas, model_dir=None)\n",
    "    model.save(model_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### y_contaminate is considered as the contaminating process in the experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "y_contaminate = np.random.randn(n_sample)\n",
    "model.update_configure(y_contaminate, gammas)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Insert the contaminated data into the clean time sequence data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "contaminated_series = get_contaminate_series(series, y_contaminate, data_sets.train.labels)\n",
    "# plot contaminated series\n",
    "# plt.plot(contaminated_series)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Interpret the Model by SIF Value\n",
    "#### In the last step, we compute SIF value. Notice that the model is inherited from SIFExplainer and the user could simply call model.explain_instance() function to get the SIF value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Regression R-squared: 0.179848\n162.92198777198792 s to compute if_v\n0.03913569450378418 s to compute patchy pred gamma\n0.0718080997467041 s to compute psi_y\nSIF = -119.54141353277345\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# compute SIF value\n",
    "sif = model.explain_instance(y_contaminate, timesteps, 1, None, 30, verbose=False)\n",
    "print('SIF = {}'.format(sif))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}